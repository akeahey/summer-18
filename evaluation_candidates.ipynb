{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "import csv\n",
    "import sys\n",
    "import glob\n",
    "# import spacy\n",
    "import pandas as pd\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load english words\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Avoid ascii error\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_poly(pl):\n",
    "    new_pl = pl.strip().strip(',').strip('.')\n",
    "    if len(new_pl)>=2 and new_pl[0] == '(' and new_pl[len(new_pl)-1]==')':\n",
    "        new_pl=new_pl.rstrip(')').lstrip('(')\n",
    "    return new_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_items(ifile):\n",
    "    items = []\n",
    "    f = open(ifile)\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        poly = cleanup_poly(line.strip(\"\\n\"))\n",
    "        upoly = u'%s' % (poly)\n",
    "        items.append(upoly)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (candidate_file, groundtruth_file):\n",
    "    \n",
    "    candidate_polymers = read_items(candidate_file)\n",
    "    extracted_polymers = read_items(groundtruth_file)\n",
    "    \n",
    "    print (len(candidate_polymers))\n",
    "    print (len(extracted_polymers))\n",
    "\n",
    "    groundtruth_polymers = [x.strip().lower() for x in extracted_polymers]\n",
    "    groundtruth_polymers = list(set(groundtruth_polymers))\n",
    "    print \"Number of polymer names in the dictionary: \", len(groundtruth_polymers)\n",
    "\n",
    "    candidate_polymers = [x.strip().lower() for x in candidate_polymers]\n",
    "    candidate_polymers = list(set(candidate_polymers))\n",
    "    print \"Number of candidate polymers in this file: \", (len(candidate_polymers))\n",
    "\n",
    "\n",
    "    # Perform evaluation (compute truth positives, false positives and false negatives)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    for candidate in candidate_polymers:\n",
    "        if candidate in groundtruth_polymers:\n",
    "            TP = TP + 1\n",
    "        else:\n",
    "            FP = FP + 1\n",
    "\n",
    "    precision = (TP/(TP+FP)*100)\n",
    "\n",
    "    FN = 0\n",
    "    for poly in groundtruth_polymers:\n",
    "        if poly not in candidate_polymers:\n",
    "            FN = FN + 1\n",
    "\n",
    "    recall = (TP/(TP+FN)*100)\n",
    "\n",
    "    print \"True pos: \", TP\n",
    "    print \"False pos: \", FP\n",
    "    print \"Precision: \", precision\n",
    "    print \"Recall: \", recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate('amber_polymer_candidates.txt', 'ground_truth_polymers_list.txt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
